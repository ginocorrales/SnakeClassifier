{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake Classifier with AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_venomous_dir = \"./Non-Venomous\"\n",
    "venomous_dir = \"./Venomous\"\n",
    "snake_data = {}\n",
    "label_dict = {}\n",
    "target_size = (224,224,3)\n",
    "#counter for species id\n",
    "i = 0\n",
    "\n",
    "for species in os.listdir(non_venomous_dir):\n",
    "    venomous_species.append(species)\n",
    "    img_list = []\n",
    "    species_folder = os.listdir(os.path.join(non_venomous_dir,species))\n",
    "    #print(species_folder)\n",
    "    label_dict[species] = i\n",
    "    for img_name in species_folder:\n",
    "        img = load_img(non_venomous_dir + \"/\" + species + \"/\" + img_name)\n",
    "        img = img.resize((224,224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_list.append(img_array)\n",
    "        img_label\n",
    "        \n",
    "    snake_data[species] = np.array(img_list)\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "for species in os.listdir(venomous_dir):\n",
    "    venomous_species.append(species)\n",
    "    img_list = []\n",
    "    species_folder = os.listdir(os.path.join(venomous_dir,species))\n",
    "    label_dict[species] = i\n",
    "    for img_name in species_folder:\n",
    "        img = load_img(venomous_dir + \"/\" + species + \"/\" + img_name)\n",
    "        img = img.resize((224,224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_list.append(img_array)\n",
    "        \n",
    "    snake_data[species] = np.array(img_list)\n",
    "    i += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "img_labels = []\n",
    "for species in snake_data:\n",
    "    for img in snake_data[species]:\n",
    "        img_array.append(img)\n",
    "        img_labels.append(label_dict[species])\n",
    "img_array = np.array(img_array)\n",
    "img_labels = np.array(img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array,img_labels = shuffle(img_array,img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percent = .8\n",
    "train_count = int(train_percent*len(img_array))\n",
    "test_count = len(img_array) - train_count\n",
    "\n",
    "train_labels = img_labels[0:train_count]\n",
    "test_labels = img_labels[train_count:]\n",
    "\n",
    "train_images = img_array[0:train_count]\n",
    "test_images = img_array[train_count:]\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_category = len(snake_data.keys())\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_category)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 13)                13013     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 13)                0         \n",
      "=================================================================\n",
      "Total params: 28,050,493\n",
      "Trainable params: 28,050,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "# Passing it to a Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3rd Fully Connected Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_category))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1423 samples, validate on 356 samples\n",
      "Epoch 1/10\n",
      "1423/1423 [==============================] - 218s 154ms/step - loss: 2.4422 - acc: 0.1455 - val_loss: 2.4308 - val_acc: 0.1208\n",
      "Epoch 2/10\n",
      "1423/1423 [==============================] - 219s 154ms/step - loss: 2.4191 - acc: 0.1363 - val_loss: 2.4254 - val_acc: 0.1348\n",
      "Epoch 3/10\n",
      "1423/1423 [==============================] - 212s 149ms/step - loss: 2.4169 - acc: 0.1469 - val_loss: 2.4216 - val_acc: 0.1348\n",
      "Epoch 4/10\n",
      "1423/1423 [==============================] - 221s 155ms/step - loss: 2.4175 - acc: 0.1363 - val_loss: 2.4246 - val_acc: 0.1208\n",
      "Epoch 5/10\n",
      "1423/1423 [==============================] - 214s 151ms/step - loss: 2.4142 - acc: 0.1434 - val_loss: 2.4268 - val_acc: 0.1348\n",
      "Epoch 6/10\n",
      "1423/1423 [==============================] - 211s 148ms/step - loss: 2.4081 - acc: 0.1342 - val_loss: 2.4242 - val_acc: 0.1348\n",
      "Epoch 7/10\n",
      "1423/1423 [==============================] - 214s 150ms/step - loss: 2.4116 - acc: 0.1441 - val_loss: 2.4241 - val_acc: 0.1348\n",
      "Epoch 8/10\n",
      "1423/1423 [==============================] - 216s 151ms/step - loss: 2.4098 - acc: 0.1448 - val_loss: 2.4253 - val_acc: 0.1348\n",
      "Epoch 9/10\n",
      "1423/1423 [==============================] - 213s 150ms/step - loss: 2.4049 - acc: 0.1476 - val_loss: 2.4375 - val_acc: 0.1208\n",
      "Epoch 10/10\n",
      "1423/1423 [==============================] - 8545s 6s/step - loss: 2.4136 - acc: 0.1370 - val_loss: 2.4256 - val_acc: 0.1348\n"
     ]
    }
   ],
   "source": [
    "#conv_model.fit(train_images,train_labels,epochs=5)\n",
    "batch_size = 1\n",
    "num_epoch = 10\n",
    "#model training\n",
    "model_log = model.fit(train_images,train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
